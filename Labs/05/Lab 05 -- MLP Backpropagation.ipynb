{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "425ac6e9-8919-4c06-be1c-782241f835f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6f6b7d-1fdf-43a4-bd7c-03d90114d3fb",
   "metadata": {},
   "source": [
    "# Lab 9 - Multi-layer Perceptron Forward Pass & Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99c1b83-fb9a-4321-882b-fd0c74d2ab1b",
   "metadata": {},
   "source": [
    "## Part I\n",
    "For this exercise you will implement a simple 2-layer perceptron with the forward pass and the backpropagation to learn the weights\n",
    "\n",
    "For the first part you'll build and train a 2-layer neural network that predicts the prices of houses, using the usual Boston housing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7804bef6-2bd6-4d05-bc4e-f9d8325f12ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "boston = pd.read_csv('./BostonHousing.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bdfc73-7702-4a3c-af9f-6fb897ec643c",
   "metadata": {
    "tags": []
   },
   "source": [
    "As usual, consider the MEDV as your target variable. \n",
    "* Split the data into training, validation and testing (70,15,15)%\n",
    "* Experiment with different number of neurons per layer for your network, using the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5df5bfc8-26c0-4d48-9c3c-05a9e404e1d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "from sklearn.model_selection import train_test_split\n",
    "# The target variable is the last column of our dataset\n",
    "X = boston.values[:,:-1]\n",
    "y = boston.values[:,1].reshape(-1, 1)\n",
    "# Now lets split the 3 results\n",
    "X_train, X_tv, y_train, y_tv = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_tv, y_tv, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8728c491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_activation(z:np.ndarray) -> np.ndarray:\n",
    "    # your code goes here\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def rmse(y_pred:np.ndarray, y_real:np.ndarray) -> float:\n",
    "    return np.sqrt(np.mean(np.power(y_pred - y_real, 2)))\n",
    "\n",
    "def sigmoid_derivative(z:np.ndarray) -> np.ndarray:\n",
    "    # your code goes here\n",
    "    return sigmoid_activation(z) * (1 - sigmoid_activation(z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcc26211-91c1-47f9-8779-eb723b0c209e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silla\\AppData\\Local\\Temp\\ipykernel_9904\\1788466481.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE para 1 neurônio(s): 24.228501118020844\n",
      "RMSE para 2 neurônio(s): 24.22849262683326\n",
      "RMSE para 3 neurônio(s): 24.023015652710665\n",
      "RMSE para 4 neurônio(s): 24.22849262675135\n",
      "RMSE para 5 neurônio(s): 23.256916877010752\n",
      "RMSE para 6 neurônio(s): 24.16080026946378\n",
      "RMSE para 7 neurônio(s): 24.228492626934194\n",
      "RMSE para 8 neurônio(s): 24.22849262675135\n",
      "RMSE para 9 neurônio(s): 24.035929285927903\n",
      "RMSE para 10 neurônio(s): 24.03748901739713\n",
      "RMSE para 11 neurônio(s): 23.201334149101033\n",
      "RMSE para 12 neurônio(s): 24.052381707381407\n",
      "RMSE para 13 neurônio(s): 24.140952954174985\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "\n",
    "def backpropagation_2layer(X:np.ndarray, y_real:np.ndarray, dim_input:int,\n",
    "                            dim_hidden:int, dim_output:int, lr:float=0.0001, repeats:int=300) -> tuple[np.ndarray]:\n",
    "    \n",
    "    # X  (n, m)\n",
    "    # Initializing weights and biases with random values\n",
    "    # First we initialize the input to hidden layers of weights and biases\n",
    "    W_input = np.random.normal(size=(dim_input, dim_hidden)) # Wi (m, h)\n",
    "    b_input = np.random.normal(size=(dim_hidden, 1)) # bi (h, 1)\n",
    "    # Then the hidden to output layers of weights and biases\n",
    "    W_output = np.random.normal(size=(dim_hidden, dim_output)) # Wo (h, o)\n",
    "    b_output = np.random.normal(size=(dim_output, 1)) # bo (o, 1)\n",
    "\n",
    "    \n",
    "    for repeat in range(repeats):\n",
    "        hidden_layer_i = X @ W_input + b_input.T # (n, m) x (m, h) -> (n, h)\n",
    "        hidden_layer_o = sigmoid_activation(hidden_layer_i)\n",
    "\n",
    "        output_layer = hidden_layer_o @ W_output + b_output.T # (n, h) x (h, o) -> (n, o)\n",
    "        error_o = output_layer - y_real # (n, o)\n",
    "\n",
    "        derivative_wo = hidden_layer_o.T @ error_o # (h, n) x (n, o) -> (h, o)\n",
    "        derivative_bo = np.sum(error_o, axis=0).reshape(-1, 1) # (o, 1)\n",
    "\n",
    "        error_h = error_o @ W_output.T * sigmoid_derivative(hidden_layer_i) # (n, o) x (o, h) -> (n, h) * (n, h)\n",
    "    \n",
    "        derivative_wi = X.T @ error_h # (m, n) x (n, h)\n",
    "        derivative_bi = np.sum(error_h, axis=0).reshape(-1, 1) # (h, 1)\n",
    "\n",
    "        W_output -= lr * derivative_wo\n",
    "        b_output -= lr * derivative_bo\n",
    "    \n",
    "        W_input -= lr * derivative_wi\n",
    "        b_input -= lr * derivative_bi\n",
    "\n",
    "    return W_input, b_input, W_output, b_output\n",
    "\n",
    "\n",
    "for i in range(1, 14):\n",
    "    hidden_layer_dim = i\n",
    "\n",
    "    W_input, b_input, W_output, b_output = backpropagation_2layer(X_train, y_train, X_train.shape[1], hidden_layer_dim, y_train.shape[1])\n",
    "    \n",
    "    y_val_pred = sigmoid_activation(X_val @ W_input + b_input.T) @ W_output + b_output.T\n",
    "    \n",
    "    val_rmse = rmse(y_val_pred, y_val)\n",
    "    print(f\"RMSE para {i} neurônio(s): {val_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6650ab-79e5-4636-a4c9-84b977c48541",
   "metadata": {},
   "source": [
    "## Part II \n",
    "\n",
    "For this exercise you will build and train a 2-layer neural network that predicts the exact digit from a hand-written image, using the MNIST dataset. \n",
    "For this exercise, add weight decay to your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bfe2473-16e8-4dce-9e5b-7d5ce1154200",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f8f04ee-c8e6-4531-9ad4-b0e530e1f92d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c49e3cd-e16a-4847-ac73-b9628f3f159a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "172b3419-d470-433f-87f9-4df67e4761e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdaf177-1cda-4c04-8d12-090678310602",
   "metadata": {},
   "source": [
    "Again, you will split the data into training, validation and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8519363c-f7e0-43a8-ba4e-a33ab9d5b96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here:\n",
    "# Now lets split the 3 results\n",
    "y = y.reshape(-1, 1)\n",
    "X_train, X_tv, y_train, y_tv = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_tv, y_tv, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "015f701c-f816-4208-8cdc-4ba32f03f08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE para 1 neurônio(s): 2.8455050874711376\n",
      "RMSE para 2 neurônio(s): 2.7292127593078224\n",
      "RMSE para 3 neurônio(s): 2.7220503707531134\n",
      "RMSE para 4 neurônio(s): 2.069302184984579\n",
      "RMSE para 5 neurônio(s): 1.9650259408562865\n",
      "RMSE para 6 neurônio(s): 1.964608048488267\n",
      "RMSE para 7 neurônio(s): 1.850462527185814\n",
      "RMSE para 8 neurônio(s): 1.9811286697185873\n",
      "RMSE para 9 neurônio(s): 1.8615370361753336\n",
      "RMSE para 10 neurônio(s): 1.805967507650367\n",
      "RMSE para 11 neurônio(s): 1.972336020938315\n",
      "RMSE para 12 neurônio(s): 2.1535412875507607\n",
      "RMSE para 13 neurônio(s): 1.8827757106681902\n"
     ]
    }
   ],
   "source": [
    "# your code goes here:\n",
    "# your code goes here\n",
    "\n",
    "def backpropagation_2layer_wd(X:np.ndarray, y_real:np.ndarray, dim_input:int,\n",
    "                            dim_hidden:int, dim_output:int, lr:float=0.0001, wd:float=0.001, repeats:int=300) -> tuple[np.ndarray]:\n",
    "    \n",
    "    # X  (n, m)\n",
    "    # Initializing weights and biases with random values\n",
    "    # First we initialize the input to hidden layers of weights and biases\n",
    "    W_input = np.random.normal(size=(dim_input, dim_hidden)) # Wi (m, h)\n",
    "    b_input = np.random.normal(size=(dim_hidden, 1)) # bi (h, 1)\n",
    "    # Then the hidden to output layers of weights and biases\n",
    "    W_output = np.random.normal(size=(dim_hidden, dim_output)) # Wo (h, o)\n",
    "    b_output = np.random.normal(size=(dim_output, 1)) # bo (o, 1)\n",
    "\n",
    "    \n",
    "    for repeat in range(repeats):\n",
    "        hidden_layer_i = X @ W_input + b_input.T # (n, m) x (m, h) -> (n, h)\n",
    "        hidden_layer_o = sigmoid_activation(hidden_layer_i)\n",
    "\n",
    "        output_layer = hidden_layer_o @ W_output + b_output.T # (n, h) x (h, o) -> (n, o)\n",
    "        error_o = output_layer - y_real # (n, o)\n",
    "\n",
    "        derivative_wo = hidden_layer_o.T @ error_o # (h, n) x (n, o) -> (h, o)\n",
    "        derivative_bo = np.sum(error_o, axis=0).reshape(-1, 1) # (o, 1)\n",
    "\n",
    "        error_h = error_o @ W_output.T * sigmoid_derivative(hidden_layer_i) # (n, o) x (o, h) -> (n, h) * (n, h)\n",
    "    \n",
    "        derivative_wi = X.T @ error_h # (m, n) x (n, h)\n",
    "        derivative_bi = np.sum(error_h, axis=0).reshape(-1, 1) # (h, 1)\n",
    "\n",
    "        derivative_wo += wd * W_output\n",
    "        derivative_wi += wd * W_input\n",
    "\n",
    "        W_output -= lr * derivative_wo\n",
    "        b_output -= lr * derivative_bo\n",
    "    \n",
    "        W_input -= lr * derivative_wi\n",
    "        b_input -= lr * derivative_bi\n",
    "\n",
    "    return W_input, b_input, W_output, b_output\n",
    "\n",
    "\n",
    "for i in range(1, 14):\n",
    "    hidden_layer_dim = i\n",
    "\n",
    "    W_input, b_input, W_output, b_output = backpropagation_2layer_wd(X_train, y_train, X_train.shape[1], hidden_layer_dim, y_train.shape[1])\n",
    "    \n",
    "    y_val_pred = sigmoid_activation(X_val @ W_input + b_input.T) @ W_output + b_output.T\n",
    "    val_rmse = rmse(y_val_pred, y_val)\n",
    "    print(f\"RMSE para {i} neurônio(s): {val_rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
