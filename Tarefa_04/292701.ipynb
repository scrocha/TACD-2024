{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe4e6d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "292701"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "292701"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a4c9d77-8ce0-4600-b5db-f98f39c8e9a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2163fb6c-8186-42af-885f-8278e7ca2ce3",
   "metadata": {},
   "source": [
    "# Tarefa 4 - Decision Trees, Random Forest and K-Means\n",
    "Fourth assessed coursework for the course: Técnicas e Algoritmos em Ciência de Dados\n",
    "\n",
    "This tarefa provides an exciting opportunity for students to put their knowledge acquired in class into practice, using decision trees and random forests to solve a real-world problem in classification and delve into the world of unsupervised learning by implementing the K-means algorithm. Students will also get used to generating important plots during training to analyse the models' behaviour. \n",
    "\n",
    "## General guidelines:\n",
    "\n",
    "* This work must be entirely original. You are allowed to research documentation for specific libraries, but copying solutions from the internet or your classmates is strictly prohibited. Any such actions will result in a deduction of points for the coursework.\n",
    "* Before submitting your work, make sure to rename the file to the random number that you created for the previous coursework (for example, 289479.ipynb).\n",
    "\n",
    "## Notebook Overview:\n",
    "\n",
    "1. [Decision Trees](#Decision_Trees) (30%)\n",
    "2. [Random Forest](#Random_Forest) (30%)\n",
    "3. [K-Means](#K-Means) (30%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698bb261-de78-4c09-bbff-f1128567f078",
   "metadata": {},
   "source": [
    "### Decision_Trees\n",
    "## Part 1 - Decision Trees for Classification (value: 30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c3fc47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "ddi_df = pd.read_csv('ddi_dt_sample.csv') # don't forget to change the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e9c360d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drug1</th>\n",
       "      <th>drug2</th>\n",
       "      <th>ddi</th>\n",
       "      <th>pca_max_0</th>\n",
       "      <th>pca_max_1</th>\n",
       "      <th>pca_max_2</th>\n",
       "      <th>pca_max_3</th>\n",
       "      <th>pca_max_4</th>\n",
       "      <th>pca_max_5</th>\n",
       "      <th>pca_max_6</th>\n",
       "      <th>...</th>\n",
       "      <th>pca_min_17</th>\n",
       "      <th>pca_min_18</th>\n",
       "      <th>pca_min_19</th>\n",
       "      <th>pca_min_20</th>\n",
       "      <th>pca_min_21</th>\n",
       "      <th>pca_min_22</th>\n",
       "      <th>pca_min_23</th>\n",
       "      <th>pca_min_24</th>\n",
       "      <th>pca_min_25</th>\n",
       "      <th>pca_min_26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CID000002725</td>\n",
       "      <td>CID000013342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.383210</td>\n",
       "      <td>-0.066904</td>\n",
       "      <td>0.051153</td>\n",
       "      <td>0.058145</td>\n",
       "      <td>0.398508</td>\n",
       "      <td>0.215271</td>\n",
       "      <td>-0.267814</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.366350</td>\n",
       "      <td>-1.091191</td>\n",
       "      <td>-1.021989</td>\n",
       "      <td>-0.086979</td>\n",
       "      <td>-0.326333</td>\n",
       "      <td>-0.179530</td>\n",
       "      <td>-0.162906</td>\n",
       "      <td>-0.204593</td>\n",
       "      <td>-0.091330</td>\n",
       "      <td>-0.195522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CID000002802</td>\n",
       "      <td>CID000013342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.554958</td>\n",
       "      <td>-0.066904</td>\n",
       "      <td>0.053715</td>\n",
       "      <td>0.058145</td>\n",
       "      <td>0.398508</td>\n",
       "      <td>0.131852</td>\n",
       "      <td>-0.267814</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.366350</td>\n",
       "      <td>0.106596</td>\n",
       "      <td>0.010149</td>\n",
       "      <td>-0.086979</td>\n",
       "      <td>-0.326333</td>\n",
       "      <td>-0.179530</td>\n",
       "      <td>-0.162906</td>\n",
       "      <td>-0.204593</td>\n",
       "      <td>-0.080100</td>\n",
       "      <td>-0.195522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CID000002083</td>\n",
       "      <td>CID000013342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.908402</td>\n",
       "      <td>-0.066904</td>\n",
       "      <td>0.122384</td>\n",
       "      <td>0.058145</td>\n",
       "      <td>0.398508</td>\n",
       "      <td>0.098734</td>\n",
       "      <td>0.041276</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.366350</td>\n",
       "      <td>0.102901</td>\n",
       "      <td>0.010149</td>\n",
       "      <td>-0.088365</td>\n",
       "      <td>-0.326333</td>\n",
       "      <td>-0.179530</td>\n",
       "      <td>-0.162906</td>\n",
       "      <td>-0.204593</td>\n",
       "      <td>-0.080100</td>\n",
       "      <td>-0.195522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CID000004034</td>\n",
       "      <td>CID000013342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.547375</td>\n",
       "      <td>-0.066904</td>\n",
       "      <td>0.051884</td>\n",
       "      <td>0.058145</td>\n",
       "      <td>0.398508</td>\n",
       "      <td>0.203962</td>\n",
       "      <td>-0.267814</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.366350</td>\n",
       "      <td>-1.011102</td>\n",
       "      <td>-0.944133</td>\n",
       "      <td>-0.086979</td>\n",
       "      <td>-0.326333</td>\n",
       "      <td>-0.179530</td>\n",
       "      <td>-0.162906</td>\n",
       "      <td>-0.204593</td>\n",
       "      <td>-0.080100</td>\n",
       "      <td>-0.195522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CID000003899</td>\n",
       "      <td>CID000013342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.554958</td>\n",
       "      <td>-0.066904</td>\n",
       "      <td>0.051083</td>\n",
       "      <td>0.058145</td>\n",
       "      <td>0.398508</td>\n",
       "      <td>0.138126</td>\n",
       "      <td>-0.267814</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.366350</td>\n",
       "      <td>0.075010</td>\n",
       "      <td>0.010149</td>\n",
       "      <td>-0.086979</td>\n",
       "      <td>-0.326333</td>\n",
       "      <td>-0.179530</td>\n",
       "      <td>-0.162906</td>\n",
       "      <td>-0.204593</td>\n",
       "      <td>-0.080100</td>\n",
       "      <td>-0.195522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>CID000002083</td>\n",
       "      <td>CID000002160</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.213277</td>\n",
       "      <td>-0.355555</td>\n",
       "      <td>0.122384</td>\n",
       "      <td>0.024324</td>\n",
       "      <td>0.144197</td>\n",
       "      <td>0.286870</td>\n",
       "      <td>0.041276</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.743211</td>\n",
       "      <td>-0.148822</td>\n",
       "      <td>0.030291</td>\n",
       "      <td>-0.088365</td>\n",
       "      <td>-0.131963</td>\n",
       "      <td>0.010439</td>\n",
       "      <td>0.014404</td>\n",
       "      <td>-0.130975</td>\n",
       "      <td>0.003776</td>\n",
       "      <td>-0.043334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>CID000002088</td>\n",
       "      <td>CID000002160</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.213277</td>\n",
       "      <td>-0.355555</td>\n",
       "      <td>0.048850</td>\n",
       "      <td>-0.064623</td>\n",
       "      <td>0.097114</td>\n",
       "      <td>0.286870</td>\n",
       "      <td>-0.235796</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.743211</td>\n",
       "      <td>-0.148822</td>\n",
       "      <td>0.041925</td>\n",
       "      <td>-0.106078</td>\n",
       "      <td>-0.131963</td>\n",
       "      <td>0.157741</td>\n",
       "      <td>-0.055455</td>\n",
       "      <td>-0.130975</td>\n",
       "      <td>-0.030832</td>\n",
       "      <td>-0.053976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>CID000001206</td>\n",
       "      <td>CID000002160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.213277</td>\n",
       "      <td>-0.355555</td>\n",
       "      <td>-0.210680</td>\n",
       "      <td>-0.646083</td>\n",
       "      <td>-0.111940</td>\n",
       "      <td>0.290024</td>\n",
       "      <td>-0.235796</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.269156</td>\n",
       "      <td>-0.148822</td>\n",
       "      <td>0.259326</td>\n",
       "      <td>-0.247741</td>\n",
       "      <td>-0.193907</td>\n",
       "      <td>0.076300</td>\n",
       "      <td>0.023777</td>\n",
       "      <td>-0.130975</td>\n",
       "      <td>0.006320</td>\n",
       "      <td>-0.070912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>CID000002118</td>\n",
       "      <td>CID000002160</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.213277</td>\n",
       "      <td>-0.355555</td>\n",
       "      <td>0.062143</td>\n",
       "      <td>-0.017338</td>\n",
       "      <td>0.059182</td>\n",
       "      <td>0.286870</td>\n",
       "      <td>-0.235796</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.743211</td>\n",
       "      <td>-0.148822</td>\n",
       "      <td>0.059779</td>\n",
       "      <td>-0.072749</td>\n",
       "      <td>-0.131963</td>\n",
       "      <td>0.077367</td>\n",
       "      <td>0.026625</td>\n",
       "      <td>-0.130975</td>\n",
       "      <td>-0.021027</td>\n",
       "      <td>-0.047147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>CID000001206</td>\n",
       "      <td>CID000002083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.908402</td>\n",
       "      <td>-0.388439</td>\n",
       "      <td>0.122384</td>\n",
       "      <td>0.024324</td>\n",
       "      <td>0.144197</td>\n",
       "      <td>0.290024</td>\n",
       "      <td>0.041276</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.269156</td>\n",
       "      <td>0.102901</td>\n",
       "      <td>0.030291</td>\n",
       "      <td>-0.247741</td>\n",
       "      <td>-0.193907</td>\n",
       "      <td>0.010439</td>\n",
       "      <td>0.014404</td>\n",
       "      <td>-0.087997</td>\n",
       "      <td>0.003776</td>\n",
       "      <td>-0.070912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>780 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            drug1         drug2  ddi  pca_max_0  pca_max_1  pca_max_2  \\\n",
       "0    CID000002725  CID000013342  0.0  -2.383210  -0.066904   0.051153   \n",
       "1    CID000002802  CID000013342  0.0  -2.554958  -0.066904   0.053715   \n",
       "2    CID000002083  CID000013342  0.0   9.908402  -0.066904   0.122384   \n",
       "3    CID000004034  CID000013342  0.0  -2.547375  -0.066904   0.051884   \n",
       "4    CID000003899  CID000013342  0.0  -2.554958  -0.066904   0.051083   \n",
       "..            ...           ...  ...        ...        ...        ...   \n",
       "775  CID000002083  CID000002160  1.0  10.213277  -0.355555   0.122384   \n",
       "776  CID000002088  CID000002160  1.0  10.213277  -0.355555   0.048850   \n",
       "777  CID000001206  CID000002160  0.0  10.213277  -0.355555  -0.210680   \n",
       "778  CID000002118  CID000002160  1.0  10.213277  -0.355555   0.062143   \n",
       "779  CID000001206  CID000002083  0.0   9.908402  -0.388439   0.122384   \n",
       "\n",
       "     pca_max_3  pca_max_4  pca_max_5  pca_max_6  ...  pca_min_17  pca_min_18  \\\n",
       "0     0.058145   0.398508   0.215271  -0.267814  ...   -0.366350   -1.091191   \n",
       "1     0.058145   0.398508   0.131852  -0.267814  ...   -0.366350    0.106596   \n",
       "2     0.058145   0.398508   0.098734   0.041276  ...   -0.366350    0.102901   \n",
       "3     0.058145   0.398508   0.203962  -0.267814  ...   -0.366350   -1.011102   \n",
       "4     0.058145   0.398508   0.138126  -0.267814  ...   -0.366350    0.075010   \n",
       "..         ...        ...        ...        ...  ...         ...         ...   \n",
       "775   0.024324   0.144197   0.286870   0.041276  ...   -0.743211   -0.148822   \n",
       "776  -0.064623   0.097114   0.286870  -0.235796  ...   -0.743211   -0.148822   \n",
       "777  -0.646083  -0.111940   0.290024  -0.235796  ...   -1.269156   -0.148822   \n",
       "778  -0.017338   0.059182   0.286870  -0.235796  ...   -0.743211   -0.148822   \n",
       "779   0.024324   0.144197   0.290024   0.041276  ...   -1.269156    0.102901   \n",
       "\n",
       "     pca_min_19  pca_min_20  pca_min_21  pca_min_22  pca_min_23  pca_min_24  \\\n",
       "0     -1.021989   -0.086979   -0.326333   -0.179530   -0.162906   -0.204593   \n",
       "1      0.010149   -0.086979   -0.326333   -0.179530   -0.162906   -0.204593   \n",
       "2      0.010149   -0.088365   -0.326333   -0.179530   -0.162906   -0.204593   \n",
       "3     -0.944133   -0.086979   -0.326333   -0.179530   -0.162906   -0.204593   \n",
       "4      0.010149   -0.086979   -0.326333   -0.179530   -0.162906   -0.204593   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "775    0.030291   -0.088365   -0.131963    0.010439    0.014404   -0.130975   \n",
       "776    0.041925   -0.106078   -0.131963    0.157741   -0.055455   -0.130975   \n",
       "777    0.259326   -0.247741   -0.193907    0.076300    0.023777   -0.130975   \n",
       "778    0.059779   -0.072749   -0.131963    0.077367    0.026625   -0.130975   \n",
       "779    0.030291   -0.247741   -0.193907    0.010439    0.014404   -0.087997   \n",
       "\n",
       "     pca_min_25  pca_min_26  \n",
       "0     -0.091330   -0.195522  \n",
       "1     -0.080100   -0.195522  \n",
       "2     -0.080100   -0.195522  \n",
       "3     -0.080100   -0.195522  \n",
       "4     -0.080100   -0.195522  \n",
       "..          ...         ...  \n",
       "775    0.003776   -0.043334  \n",
       "776   -0.030832   -0.053976  \n",
       "777    0.006320   -0.070912  \n",
       "778   -0.021027   -0.047147  \n",
       "779    0.003776   -0.070912  \n",
       "\n",
       "[780 rows x 57 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the data\n",
    "ddi_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf94b3a6",
   "metadata": {},
   "source": [
    "As you can observe, the first 2 columns represent the IDs of the drugs in each combination. The 3rd column represents the binary label indicating if the pair causes an adverse interaction or not. The remaining 54 columns are the features based on the PCA representations of individual drug targets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51329343-9ecb-4e89-8b7b-bdfd62c4d777",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## your code goes here:\n",
    "# Start spliting the data\n",
    "random_state = 0\n",
    "X_ddi = ddi_df.values[:,3:]\n",
    "y_ddi = ddi_df.values[:,2]\n",
    "X_ddi_train, X_ddi_test, y_ddi_train, y_ddi_test = train_test_split(X_ddi, y_ddi, test_size=0.1, random_state=random_state)\n",
    "y_ddi_train = y_ddi_train.reshape(-1, 1)\n",
    "y_ddi_test = y_ddi_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59460160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's reuse the code from lab 06 but with some diferences to calculate the entropy\n",
    "def entropy(y:np.ndarray) -> float:\n",
    "    entropy = 0\n",
    "    for classe in np.unique(y):\n",
    "        proporcao = np.size(y[y==classe])/len(y)\n",
    "\n",
    "        entropy += proporcao * np.log2(proporcao)\n",
    "\n",
    "    return -entropy\n",
    "\n",
    "def split_region(region:np.ndarray, feature_index:int, tau:float) -> tuple[np.ndarray]:\n",
    "    feature = region[:,feature_index]\n",
    "\n",
    "    left_partition = np.where(feature < tau)[0]\n",
    "    right_partition = np.where(feature >= tau)[0]\n",
    "\n",
    "    return left_partition, right_partition\n",
    "\n",
    "def info_gain(y:np.ndarray, left_split:np.ndarray, right_split:np.ndarray) -> float:\n",
    "    # Entropia antes da divisão\n",
    "    start_entropy = entropy(y)\n",
    "    \n",
    "    # Entropia dos subgrupos\n",
    "    entropy_left = entropy(y[left_split])\n",
    "    size_left = len(left_split) / len(y)\n",
    "    \n",
    "    entropy_right = entropy(y[right_split])\n",
    "    size_right = len(right_split) / len(y)\n",
    "    \n",
    "    final_entropy = size_left * entropy_left + size_right * entropy_right\n",
    "    \n",
    "    # Ganho de informação\n",
    "    return start_entropy - final_entropy\n",
    "\n",
    "def get_split(X: np.ndarray, y: np.ndarray) -> dict:\n",
    "    feature_index = 0\n",
    "    best_tau = 0\n",
    "    best_error = float(\"-inf\")\n",
    "    left_region = list()\n",
    "    right_region = list()\n",
    "\n",
    "    for col in range(X.shape[1]):\n",
    "        sorted_values = np.sort(np.unique(X[:, col]))\n",
    "        taus = (sorted_values[:-1] + sorted_values[1:]) / 2\n",
    "\n",
    "        for tau in taus:\n",
    "            left_split, right_split = split_region(X, col, tau)\n",
    "            criterion = info_gain(y, left_split, right_split)\n",
    "\n",
    "            if criterion > best_error:\n",
    "                feature_index = col\n",
    "                best_tau = tau\n",
    "                best_error = criterion\n",
    "                left_region = left_split\n",
    "                right_region = right_split\n",
    "\n",
    "    return {\"feature_index\": feature_index, \"tau\": best_tau, \"left_region\": left_region, \"right_region\": right_region}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f10b2b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then let's implement the recursive growth\n",
    "def train_tree(X:np.ndarray, y:np.ndarray, node:dict, min_samples:int, max_depth:int, current_depth:int=0) -> None:\n",
    "    if len(y) <= min_samples or current_depth >= max_depth or entropy(y) == 0:\n",
    "        node[\"value\"] = np.mean(y)\n",
    "        return\n",
    "    \n",
    "    split = get_split(X, y)\n",
    "    left_region = split[\"left_region\"]\n",
    "    right_region = split[\"right_region\"]\n",
    "\n",
    "    if len(left_region) == 0 or len(right_region) == 0:\n",
    "        node[\"value\"] = np.mean(y)\n",
    "        return\n",
    "\n",
    "    node[\"feature_index\"] = split[\"feature_index\"]\n",
    "    node[\"tau\"] = split[\"tau\"]\n",
    "    node[\"left\"] = {}\n",
    "    node[\"right\"] = {}\n",
    "    current_depth += 1\n",
    "\n",
    "    train_tree(X[left_region], y[left_region], node[\"left\"], min_samples, max_depth, current_depth)\n",
    "    train_tree(X[right_region], y[right_region], node[\"right\"], min_samples, max_depth, current_depth)\n",
    "\n",
    "def create_tree(X:np.ndarray, y:np.ndarray, min_samples:int, max_depth:int) -> None:\n",
    "    node = dict()\n",
    "    train_tree(X, y, node, min_samples, max_depth)\n",
    "    return node\n",
    "\n",
    "def predict_sample(node:dict, sample:np.ndarray) -> float:\n",
    "    if \"value\" in node:\n",
    "        return node[\"value\"]\n",
    "    \n",
    "    feature_index = node[\"feature_index\"]\n",
    "    tau = node[\"tau\"]\n",
    "    \n",
    "    if sample[feature_index] < tau:\n",
    "        return predict_sample(node[\"left\"], sample)\n",
    "    else:\n",
    "        return predict_sample(node[\"right\"], sample)\n",
    "        \n",
    "def predict(node:dict, X:np.ndarray) -> np.ndarray:\n",
    "    predictions = list()\n",
    "    for i in range(len(X)):\n",
    "        x_sample = X[i, :]\n",
    "        predictions.append(predict_sample(node, x_sample))\n",
    "    y_pred = np.array(predictions).reshape(-1, 1)\n",
    "    \n",
    "    y_pred[y_pred >= 0.5] = 1\n",
    "    y_pred[y_pred < 0.5] = 0\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "def get_accuracy_tree(tree:dict, X:np.ndarray, y:np.ndarray) -> float:\n",
    "    predictions = predict(tree, X)\n",
    "    accuracy = np.sum(predictions.astype(int) == y.astype(int))/len(y)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d466a15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for depth 4: 0.698005698005698\n",
      "AUROC for depth 4: 0.7181081406392051\n",
      "Accuracy for depth 6: 0.7891737891737892\n",
      "AUROC for depth 6: 0.8008333744327837\n",
      "Accuracy for depth 8: 0.7934472934472935\n",
      "AUROC for depth 8: 0.7910752014574224\n"
     ]
    }
   ],
   "source": [
    "def cross_validation(X_train:np.ndarray, y_train:np.ndarray, min_samples:int, max_depth:int, n_splits=3):\n",
    "    indices = np.arange(len(X_train))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    fold_indices = np.array_split(indices, n_splits)\n",
    "\n",
    "    accuracies = list()\n",
    "    aurocs = list()\n",
    "\n",
    "    for i in range(n_splits):\n",
    "        val_indices = fold_indices[i]\n",
    "        train_indices = np.concatenate([fold_indices[j] for j in range(n_splits) if j != i])\n",
    "\n",
    "        X_train_fold, X_val_fold = X_train[train_indices], X_train[val_indices]\n",
    "        y_train_fold, y_val_fold = y_train[train_indices].reshape(-1, 1), y_train[val_indices].reshape(-1, 1)\n",
    "\n",
    "        tree = create_tree(X_train_fold, y_train_fold, min_samples, max_depth)\n",
    "\n",
    "        y_pred_val = predict(tree, X_val_fold)\n",
    "\n",
    "        accuracy_fold = get_accuracy_tree(tree, X_val_fold, y_val_fold)\n",
    "        auroc_fold = roc_auc_score(y_val_fold.astype(int), y_pred_val.astype(int))\n",
    "\n",
    "        accuracies.append(accuracy_fold)\n",
    "        aurocs.append(auroc_fold)\n",
    "\n",
    "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "    avg_auroc = sum(aurocs) / len(aurocs)\n",
    "\n",
    "    return avg_accuracy, avg_auroc\n",
    "\n",
    "min_samples = 15\n",
    "max_depths = [4, 6, 8]\n",
    "best_depth = None\n",
    "best_auroc = 0\n",
    "\n",
    "for depth in max_depths:\n",
    "    avg_accuracy, avg_auroc = cross_validation(X_ddi_train, y_ddi_train, min_samples, depth)\n",
    "    \n",
    "    if avg_auroc > best_auroc:\n",
    "        best_auroc = avg_accuracy\n",
    "        best_depth = depth\n",
    "\n",
    "    print(f\"Accuracy for depth {depth}: {avg_accuracy}\")\n",
    "    print(f\"AUROC for depth {depth}: {avg_auroc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57abd41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set Accuracy: 0.8076923076923077\n",
      "Test set AUROC: 0.7989130434782609\n"
     ]
    }
   ],
   "source": [
    "tree = create_tree(X_ddi_train, y_ddi_train, min_samples, best_depth)\n",
    "\n",
    "y_pred_test = predict(tree, X_ddi_test)\n",
    "\n",
    "accuracy_test = get_accuracy_tree(tree, X_ddi_test, y_ddi_test)\n",
    "auroc_test = roc_auc_score(y_ddi_test.astype(int), y_pred_test.astype(int))\n",
    "\n",
    "print(\"Test set Accuracy:\", accuracy_test)\n",
    "print(\"Test set AUROC:\", auroc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43a1622-54da-4aa8-a1c2-00f3241292be",
   "metadata": {},
   "source": [
    "## Random_Forest\n",
    "## Part 2 - Random Forest for Classification Networks (value: 30%)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ae13d9f-4ef0-4735-8190-1bcaaa28ea2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## your code goes here:\n",
    "X_ddi_train, X_ddi_tv, y_ddi_train, y_ddi_tv = train_test_split(X_ddi, y_ddi, test_size=0.2, random_state=random_state)\n",
    "X_ddi_val, X_ddi_test, y_ddi_val, y_ddi_test = train_test_split(X_ddi_tv, y_ddi_tv, test_size=0.5, random_state=random_state)\n",
    "\n",
    "y_ddi_train, y_ddi_val, y_ddi_test = y_ddi_train.reshape(-1, 1), y_ddi_val.reshape(-1, 1), y_ddi_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6975abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_ddi_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2950e57-8657-4066-b657-1c96c830ce6e",
   "metadata": {},
   "source": [
    "## K-Means\n",
    "## Part 3 – Clustering with K-means (value: 40%)\n",
    "\n",
    "In this exercise, you will explore clustering by implementing the K-means algorithm. You will write code to perform K-means clustering while visualizing the movement of the centroids at each iteration. \n",
    "\n",
    "To complete this exercise, you will write code to implement K-means for clustering: \n",
    "\n",
    "1. Dataset Preparation: Run the cells provided in the notebook that generate the artificial data points for this exercise.\n",
    "2. K-means Clustering:\n",
    "\t- Initialize K cluster centroids by selecting K points from your dataset at random.\n",
    "\t- Implement a loop to perform the following steps until convergence (or until a specified maximum number of iterations is reached, e.g., 150):\n",
    "        - Assign each data point to the nearest centroid (you will have to calculate the Euclidean distance between the data point and each centroid).\n",
    "        - Update each centroid by moving it to the mean of all data points assigned to it.\n",
    "        - Check for convergence by comparing the new centroids with the previous centroids. If the difference is smaller than an $\\epsilon=1^{-4}$, exit the loop.\n",
    "3. Centroid Movement Visualization:\n",
    "\t- At 5 different moments during training, plot a figure showing the centroids and the points. Figure 1 should show the situation at the beginning, before learning. Figure 5 should show the situation at the end of the learning. The remaining Figures 2-4 should show intermediary situations.\n",
    "\t- For each figure, each centroid will be represented by a large black cross and each cluster with a different colour, the points must be coloured according to their respective cluster.\n",
    "4. Sum of squared distances:\n",
    "\t- Along with plotting the centroid movement, calculate the sum of squared distances at each iteration as follows:\n",
    "        - $\\sum_{j=1}^K \\sum_{n \\in S_j}d(x_n,\\mu_j )^2$, where $K$ is the number of clusters, $x_n$ represents the $n^{th}$ datapoint, $n \\in S_j$ indicates a set of points that belong to cluster $S_j$, $\\mu_j$ is the mean of the datapoints in $S_j$ and $d(x_n,\\mu_j)$ indicates the Euclidean distance between $x_n$ and $\\mu_j$.\n",
    "\t- Make a plot of the sum of squared distances at each iteration. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a03418cb-b1b2-4fd8-b0e9-6d1a21ae5882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate artificial data points\n",
    "np.random.seed(13)\n",
    "num_samples = 200\n",
    "num_features = 2\n",
    "X = np.random.randn(num_samples, num_features) * 1.5 + np.array([[2, 2]])\n",
    "X = np.concatenate([X, np.random.randn(num_samples, num_features) * 3 + np.array([[-5, -5]])])\n",
    "X = np.concatenate([X, np.random.randn(num_samples, num_features) * 2 + np.array([[7, -5]])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47b782b9-0bd4-4085-a5f2-f55ca13208eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code goes here:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
