{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd71f212-b8dc-4f83-a4c9-4b2a5b7e8625",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Place here the same 6-digit number you selected for the first coursework. \n",
    "# Make sure that you keep a copy of this number and avoid trivial numbers, such as 000000 or 123456 -- thank you!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05468eb-e9d9-44b3-80f7-d1e1dc7296b1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Assignment 2 - Regression and Classification\n",
    "\n",
    "Second assessed coursework for the course: Técnicas e Algoritmos em Ciência de Dados\n",
    "\n",
    "This coursework aims to provide students with a comprehensive understanding of linear regression with polynomial basis functions and classification with K-nearest neighbours. Specifically, students will learn about key concepts related to the model's generalisation ability by changing the degree of the polynomial and the size of the dataset. In the second part of the coursework, students will delve into classification using the K-nearest neighbours algorithm. Finally, students will be introduced to the concept of using a validation set to select the optimal value of $K$ for their classification model. By the end of this coursework, students will have gained a solid understanding of these key concepts and be equipped with the skills to apply them in practical scenarios.\n",
    "\n",
    "## General guidelines:\n",
    "\n",
    "* This work must be entirely original. You are allowed to research documentation for specific libraries, but copying solutions from the internet or your classmates is strictly prohibited. Any such actions will result in a deduction of points for the coursework.\n",
    "* Please enter your code in the designated areas of the notebook. You can create additional code cells to experiment with, but __make sure to place your final solutions where they are requested in the notebook.__\n",
    "* Before submitting your work, make sure to rename the file to the random number that you created for the previous coursework (for example, 289479.ipynb).\n",
    "\n",
    "## Notebook Overview:\n",
    "\n",
    "1. [Polynomial Fitting Visualisation](#Polynomial-Fitting-Visualisation) (50%)\n",
    "2. [Classification with KNN](#Classification-with-KNN) (50%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bbccb7a-e176-497e-afe5-107d94f6ccf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1e05a8-860b-45c1-9e23-1e2ae348d7ee",
   "metadata": {},
   "source": [
    "# Polynomial Fitting Visualisation\n",
    "In this exercise you will explore the effect that the degree of the polynomial and the size of the training data has on the model's performance and generalisation ability.\n",
    "\n",
    "1. Generate a 2D dataset of 15 points $(x_i,y_i)$ for $i=1..15$ using a sine wave perturbed by a small gaussian noise --- this is very similar to what you did in the lab.\n",
    "    - The $x_i$ should be equally spaced in the $[0-10]$ interval \n",
    "    - Use: $y_i = 4*sin(x_i) + \\epsilon$, where $\\epsilon$ is gaussian noise (with $\\mu=0$ and $\\sigma=1$).\n",
    "    - To ensure reproducibility of your results, use (provided below): \n",
    "    `rng = np.random.default_rng(13)` and\n",
    "    `random_state = np.random.RandomState(13)`\n",
    "    \n",
    "2. Split the points randomly into a training and testing sets of size 10 and 5, respectively.\n",
    "    \n",
    "3. Learn the weights of the linear regression for  polynomial models of degree $M$ for $M = 0..9$ . For each value of $M$ calculate the Root Mean Squared Error (RMSE) for the training and testing sets and plot these values against $M$. Your figure should be similar to Figure 1 from the Coursework document.\n",
    "\n",
    "4. In the last part of this exercise, you will have to create more points for training (using the same sine wave perturbed by a small gaussian noise as described in point 1). For testing, you will continue to use the same 5 points you used in points 1 to 3. Learn the weights of the linear regression for  polynomial models of degree $M=9$ for training sets of size $N$ with $N=10:500:10$ (that is, from $N=10$ to $N=500$ in steps of $10$). For each value of $N$ calculate the Root Mean Squared Error (RMSE) for the training and testing sets and plot these values against $N$. Your figure should be similar to Figure 2 from the Coursework document.\n",
    "\n",
    "* Note that for parts 3 and 4 you are supposed to write your code from scratch and you cannot use existing functions such as `PolynomialFeatures`, `LinearRegression` or `mean_squared_error`.\n",
    "* _Observation: in this exercise we are not using the validation set because our goal is not to choose a specific model but rather to analyse the behaviour of the family of models._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da4fed1-c4ad-4b5d-914b-0debae29f1b6",
   "metadata": {},
   "source": [
    "### Generate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748c64e9-3c3e-4e25-88d5-ac8943bc4671",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(13)\n",
    "random_state = np.random.RandomState(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11f869dc-1b96-4aaa-b2d9-d2ad0c709d84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code goes here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c1ce30-85ed-4c2b-8a16-0b9b3a5096b4",
   "metadata": {},
   "source": [
    "### Split the points into training and testing\n",
    "Feel free to use `train_test_split(x, y, test_size = ?, random_state = random_state)`, remember to calculate the right proportion for the `test_size` so that you end up with 5 points in the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756d1c8f-c2b9-453b-99e2-4d556e8a60a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6597f4-0af5-4fa7-929b-4f3f8b02c61c",
   "metadata": {},
   "source": [
    "### Degree vs. RMSE\n",
    "Generate the plot (as in __Figure 1__) of the RMSE during training and testing at different values of of the polynomial degree $M$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d86279b-109e-4ff0-9f32-6f8c0a1b5f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395409e1-7280-4420-88ed-2fc635b914d0",
   "metadata": {},
   "source": [
    "### Training set size vs. RMSE\n",
    "Generate the plot (as in __Figure 2__) of the RMSE during training and testing at different training set sizes $N$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc515bf6-c077-49c0-928d-a1300f3967e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6315547-1273-42ae-973a-0825c2312804",
   "metadata": {},
   "source": [
    "# Classification with KNN\n",
    "In this exercise you will implement the K-nearest neighbours (K-NN) algorithm for multi-class classification and use it to classify the Wine dataset. You will also need to determine the optimal value of $K$ using the accuracy on a validation set and report the test set performance based on the accuracy.\n",
    "\n",
    "Dataset: The Wine dataset contains the results of a chemical analysis of wines grown in the same region in Italy but derived from three different cultivars. The analysis determined the quantities of 13 constituents found in each of the three types of wines. The dataset contains 178 observations, with 13 attributes each. There are three different classes of wines.\n",
    "\n",
    "Specifically:\n",
    "1. 1.\tLoad the Wine dataset and split it into a training set ($70\\%$), a validation set ($15\\%$), and a testing set ($15\\%$).\n",
    "    \n",
    "2. You will write code that implements the K-NN algorithm for multi-class classification. Use Euclidean distance as the distance metric.\n",
    "    - _Obs: it is better if you take only odd values of K, considering you are predicting the class based on the majority of the neighbours._\n",
    "\n",
    "\n",
    "3. Use the K-NN algorithm on the training set for a range of values of $K$ and evaluate its performance on the validation set using the accuracy. Plot the accuracy on the validation set against the range of values that were tried for $K$. Your plot should look like Figure 3. \n",
    "    - *Observation: it is better if you take only odd values of K, considering you are predicting the class based on the majority of the neighbours.*\n",
    "    - **You will also have to implement the accuracy-score from scratch.**\n",
    "\n",
    "\n",
    "4. \tChoose the value of $K$ that gives the best accuracy score in point 3 and report the accuracy of the K-NN algorithm on the test set using the selected value of $K$.\n",
    "\t- *Observation: when obtaining the predictions for the testing set, remember to include the validation set in your training set.*\n",
    "\n",
    "\n",
    "\n",
    "* __Note:__ You are not allowed to use any Python libraries such as scikit-learn to implement the K-NN algorithm or to calculate distances or the accuracy score. You may use numpy or other basic libraries for matrix operations.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08168d9-c8d3-496c-b24e-3c6aa92cc406",
   "metadata": {},
   "source": [
    "### Preparing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3644c7b-3b33-4595-b49c-29b9a53ca088",
   "metadata": {},
   "source": [
    "Load the dataset and generate the training, validation and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "836ed810-8ac1-4781-b4b7-ac9d46762ab6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_wine = pd.read_csv('X_wine.csv')\n",
    "y_wine = pd.read_csv('y_wine.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aec99a-7224-4d05-a4f3-23259d621b88",
   "metadata": {},
   "source": [
    "Let's inspect the dataset. There are 13 features and one target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec8beb33-b369-4fd7-a8f9-2eaa9e2ba92f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malicacid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity_of_ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid_phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>0D280_0D315_of_diluted_wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alcohol  Malicacid   Ash  Alcalinity_of_ash  Magnesium  Total_phenols  \\\n",
       "0    14.23       1.71  2.43               15.6        127           2.80   \n",
       "1    13.20       1.78  2.14               11.2        100           2.65   \n",
       "2    13.16       2.36  2.67               18.6        101           2.80   \n",
       "3    14.37       1.95  2.50               16.8        113           3.85   \n",
       "4    13.24       2.59  2.87               21.0        118           2.80   \n",
       "\n",
       "   Flavanoids  Nonflavanoid_phenols  Proanthocyanins  Color_intensity   Hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   0D280_0D315_of_diluted_wines  Proline  \n",
       "0                          3.92     1065  \n",
       "1                          3.40     1050  \n",
       "2                          3.17     1185  \n",
       "3                          3.45     1480  \n",
       "4                          2.93      735  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_wine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780db93b-1cb3-4b48-8c3a-4980acb0d403",
   "metadata": {},
   "source": [
    "We can inspect the class distribution by using `value_counts()` on the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d45c38ad-e30c-4f0a-823e-aa8f89eec215",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "2        71\n",
       "1        59\n",
       "3        48\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_wine.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5268baac-164d-4c23-92d2-fa5eeffca5bb",
   "metadata": {},
   "source": [
    "Now you will write code to split the data into training ($70\\%$), validation ($15\\%$), and testing ($15\\%$). \n",
    "\n",
    "You can use `train_test_split()` but make sure to calculate the right proportions and remember that this only returns 2 different sets, not 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92a12994-bbac-4ba3-b115-0de949b87231",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set the random_state for reproducibilty of your results\n",
    "random_state = 113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f9fff4-e811-41a0-940b-1539a002c3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36e0e12-6f05-415e-9736-e980667818c3",
   "metadata": {},
   "source": [
    "### Here you will implement the KNN algorithm using the euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87585ca3-a5f7-4155-822d-bafcc3be3d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(x1, x2):\n",
    "    # your code goes here:\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56f6ba5-944e-4109-b423-7dec4890036a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_predict():\n",
    "    # your code goes here:\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1443e168-3fec-40a9-84e5-a5bb3e03352d",
   "metadata": {},
   "source": [
    "### Select the optimal $K$ by plotting the accuracy score in the validation set at different values of $K$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ec49e0-84eb-41e5-a6d3-b124520f2aa6",
   "metadata": {},
   "source": [
    "First create a function that calculates the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6179ed96-a064-4c7b-8f6b-aa11425da940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_acc_score():\n",
    "    # your code goes here:\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6df1af4-5361-4cb3-baaa-23ae6470c0e2",
   "metadata": {},
   "source": [
    "Generate the plot and select the optimal $K$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ae15c8-b904-4383-92a1-616bd0f3b4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08575674-1b72-4c31-90c2-8e3891af6762",
   "metadata": {},
   "source": [
    "Calculate the test set performance using the optimal $K$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7c6e2a-84a0-42ea-9b7f-b343072355cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here:\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
